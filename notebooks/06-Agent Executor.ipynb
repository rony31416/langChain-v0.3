{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f164c90",
   "metadata": {},
   "source": [
    "# LangChain Agent Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97f030e",
   "metadata": {},
   "source": [
    "In this chapter, we will continue from the [introduction to agents](https://aurelio.ai/learn/langchain-agents-intro) and dive deeper into agents. Learning how to build our custom agent execution loop for v0.3 of LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec034d",
   "metadata": {},
   "source": [
    "## What is the Agent Executor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161afb1",
   "metadata": {},
   "source": [
    "When we talk about agents, a significant part of an \"agent\" is simple code logic,\n",
    "iteratively rerunning LLM calls and processing their output. The exact logic varies\n",
    "significantly, but one well-known example is the **ReAct** agent.\n",
    "\n",
    "![ReAct process](../assets/ai-agents-00.png)\n",
    "\n",
    "**Re**ason + **Act**ion (ReAct) agents use iterative _reasoning_ and _action_ steps to\n",
    "incorporate chain-of-thought and tool-use into their execution. During the _reasoning_\n",
    "step, the LLM generates the steps to take to answer the query. Next, the LLM generates\n",
    "the _action_ input, which our code logic parses into a tool call.\n",
    "\n",
    "![Agentic graph of ReAct](../assets/ai-agents-01.png)\n",
    "\n",
    "Following our action step, we get an observation from the tool call. Then, we feed the\n",
    "observation back into the agent executor logic for a final answer or further reasoning\n",
    "and action steps.\n",
    "\n",
    "The agent and agent executor we will be building will follow this pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245c433",
   "metadata": {},
   "source": [
    "## Step 1: Understanding the Big Picture \n",
    "### What is an Agent?\n",
    "Think of an agent like a smart assistant that can:\n",
    "- Understand what you want\n",
    "- Decide which tools to use\n",
    "- Use those tools step by step\n",
    "- Give you a final answer\n",
    "\n",
    "### How Does It Work?\n",
    "```\n",
    "You: \"What is 5 + 3 multiplied by 2?\"\n",
    "\n",
    "Agent thinks: \n",
    "1. \"I need to add 5 + 3 first\"\n",
    "2. \"Then multiply the result by 2\"\n",
    "3. \"Let me use my add tool, then multiply tool\"\n",
    "\n",
    "Agent: \"The answer is 16\"\n",
    "```\n",
    "\n",
    "### Why Build Our Own?\n",
    "- **Free**: No API costs\n",
    "- **Private**: Your data stays on your computer  \n",
    "- **Customizable**: Add any tools you want\n",
    "- **Educational**: Learn how AI agents really work\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ecad0",
   "metadata": {},
   "source": [
    "## Step 2: Setting Up Our Environment ðŸ› ï¸\n",
    "\n",
    "### Step 2a: Install Required Packages\n",
    "```python\n",
    "# First, let's install what we need\n",
    "# Run this in your terminal or notebook:\n",
    "# pip install langchain-community langchain-core ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67512876",
   "metadata": {},
   "source": [
    "### Step 2b: Import Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0c5b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic libraries imported!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Think of imports like getting tools from a toolbox\n",
    "import json  # For handling structured data (like recipes)\n",
    "import re   # For finding patterns in text (like finding phone numbers)\n",
    "from typing import Dict, List, Any, Optional  # For being clear about data types\n",
    "\n",
    "print(\"Basic libraries imported!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a078e",
   "metadata": {},
   "source": [
    "**Why do we need these?**\n",
    "- `json`: Our agent will \"speak\" in JSON format (structured data)\n",
    "- `re`: To find and extract JSON from the model's responses\n",
    "- `typing`: To make our code clear and prevent bugs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3dfc0c",
   "metadata": {},
   "source": [
    "### Step 2c: Import LangChain Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92cab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain components imported!\n"
     ]
    }
   ],
   "source": [
    "# LangChain is like a toolkit for building AI applications\n",
    "from langchain_core.tools import tool  # For creating our math tools\n",
    "from langchain_core.prompts import ChatPromptTemplate  # For creating instructions\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage  # For conversation\n",
    "from langchain_community.llms import Ollama  # For connecting to our local AI model\n",
    "\n",
    "print(\"LangChain components imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef84f0",
   "metadata": {},
   "source": [
    "\n",
    "**What is LangChain?**\n",
    "- It's like LEGO blocks for AI applications\n",
    "- Provides pre-built components we can snap together\n",
    "- Makes building AI apps much easier\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5fe58",
   "metadata": {},
   "source": [
    "## Step 3: Creating Simple Math Tools \n",
    "\n",
    "### Step 3a: Understanding the @tool Decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62cdf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool result: 8.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "# Call using invoke\n",
    "result = add.invoke({\"x\": 5, \"y\": 3})\n",
    "print(f\"Tool result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9855b1",
   "metadata": {},
   "source": [
    "**What just happened?**\n",
    "- The `@tool` decorator turns our function into something special\n",
    "- It keeps track of the function name and description\n",
    "- The description in triple quotes is important - it tells our AI what this tool does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c585da",
   "metadata": {},
   "source": [
    "### Step 3b: Creating Our Basic Math Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5583e800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All math tools created!\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract x from y (y - x).\"\"\"\n",
    "    result = y - x\n",
    "    print(f\" Calculating {y} - {x} = {result}\")\n",
    "    return result\n",
    "\n",
    "@tool  \n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply two numbers together.\"\"\"\n",
    "    result = x * y\n",
    "    print(f\" Multiplying {x} Ã— {y} = {result}\")\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise x to the power of y (x^y).\"\"\"\n",
    "    result = x ** y\n",
    "    print(f\" Calculating {x}^{y} = {result}\")\n",
    "    return result\n",
    "\n",
    "print(\" All math tools created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3c1770",
   "metadata": {},
   "source": [
    "\n",
    "**Why these specific tools?**\n",
    "- They cover basic math operations\n",
    "- Each has a clear, single purpose\n",
    "- The print statements help us debug (see what's happening)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f80a6",
   "metadata": {},
   "source": [
    "### Step 3c: Creating the Special \"Final Answer\" Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8775fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer tool created!\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def final_answer(answer: str, tools_used: List[str]) -> Dict[str, Any]:\n",
    "    \"\"\"Provide the final answer to the user.\n",
    "    \n",
    "    Args:\n",
    "        answer: The final answer in natural language\n",
    "        tools_used: List of tool names that were used\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"answer\": answer,\n",
    "        \"tools_used\": tools_used\n",
    "    }\n",
    "    print(f\"Final Answer: {answer}\")\n",
    "    print(f\"Tools Used: {tools_used}\")\n",
    "    return result\n",
    "\n",
    "print(\"Final answer tool created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51142ebc",
   "metadata": {},
   "source": [
    "**Why do we need a \"final answer\" tool?**\n",
    "- It signals when our agent is done calculating\n",
    "- It provides a nice summary of what was done\n",
    "- It gives us the answer in human-friendly language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6daaa",
   "metadata": {},
   "source": [
    "### Step 3d: Organizing Our Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ac800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools:\n",
      "1. add: Add two numbers together.\n",
      "2. subtract: Subtract x from y (y - x).\n",
      "3. multiply: Multiply two numbers together.\n",
      "4. exponentiate: Raise x to the power of y (x^y).\n",
      "5. final_answer: Provide the final answer to the user.\n",
      "\n",
      "    Args:\n",
      "        answer: The final answer in natural language\n",
      "        tools_used: List of tool names that were used\n",
      "\n",
      "Tool dictionary created with 5 tools\n"
     ]
    }
   ],
   "source": [
    "# Put all our tools in a list\n",
    "tools = [add, subtract, multiply, exponentiate, final_answer]\n",
    "\n",
    "# Create a dictionary to easily find tools by name\n",
    "name2tool = {tool.name: tool.func for tool in tools}\n",
    "\n",
    "print(\"Available tools:\")\n",
    "for i, tool in enumerate(tools, 1):\n",
    "    print(f\"{i}. {tool.name}: {tool.description}\")\n",
    "\n",
    "print(f\"\\nTool dictionary created with {len(name2tool)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea4c92",
   "metadata": {},
   "source": [
    "**What's this dictionary for?**\n",
    "- When our AI says \"use the add tool\", we need to find the actual function\n",
    "- The dictionary lets us look up tools by name quickly\n",
    "- Like a phone book, but for functions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8554f09b",
   "metadata": {},
   "source": [
    "## Step 4: Understanding Why Ollama is Different "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c70ded",
   "metadata": {},
   "source": [
    "### Step 4a: The OpenAI Way (What We Can't Do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd42c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama doesn't support bind_tools()\n",
      "So we'll build our own system!\n"
     ]
    }
   ],
   "source": [
    "# This is what the original notebook did with OpenAI:\n",
    "# \n",
    "# llm.bind_tools(tools, tool_choice=\"any\")\n",
    "# \n",
    "# This magically tells OpenAI about our tools and it can call them directly\n",
    "# But Ollama doesn't have this feature!\n",
    "\n",
    "print(\"Ollama doesn't support bind_tools()\")\n",
    "print(\"So we'll build our own system!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f2c1cf",
   "metadata": {},
   "source": [
    "### Step 4b: Our Creative Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56748edb",
   "metadata": {},
   "source": [
    "### Instead of magic function calling, we'll:\n",
    "- 1. Tell the AI about our tools in plain English\n",
    "- 2. Ask it to respond with JSON format\n",
    "- 3. Parse that JSON to see which tool it wants to use\n",
    "- 4. Run the tool ourselves\n",
    "- 5. Give the result back to the AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6656d5a",
   "metadata": {},
   "source": [
    "## Step 5: Setting Up Ollama Connection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15683372",
   "metadata": {},
   "source": [
    "### Step 5a: Install and Start Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c1c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ollama setup checklist:\n",
      " Ollama installed\n",
      " Model downloaded (ollama pull llama2)\n",
      " Ollama server running (ollama serve)\n",
      "\n",
      "If any of these aren't done, do them first!\n"
     ]
    }
   ],
   "source": [
    "# Before running this code, you need to:\n",
    "# 1. Install Ollama: https://ollama.ai\n",
    "# 2. Download a model: ollama pull llama2\n",
    "# 3. Start Ollama: ollama serve\n",
    "\n",
    "print(\" Ollama setup checklist:\")\n",
    "print(\" Ollama installed\")\n",
    "print(\" Model downloaded (ollama pull llama2)\")  \n",
    "print(\" Ollama server running (ollama serve)\")\n",
    "print(\"\\nIf any of these aren't done, do them first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fcc253",
   "metadata": {},
   "source": [
    "### Step 5b: Connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dfc6b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USERAS\\AppData\\Local\\Temp\\ipykernel_9500\\3214559778.py:13: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm here and ready to help. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Initialize the Ollama LLM\n",
    "llm = Ollama(\n",
    "    model=\"llama3.2\",  # Model name\n",
    "    temperature=0.0,    # Lower temperature for more deterministic outputs\n",
    "    base_url=\"http://localhost:11434\"  # Default Ollama server URL\n",
    ")\n",
    "\n",
    "# Test the connection\n",
    "response = llm.invoke(\"Hello, are you working?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c84ad90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ollama connected! Test response: 1, 2, 3.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    test_response = llm.invoke(\"Hello! Can you count to 3?\")\n",
    "    print(f\" Ollama connected! Test response: {test_response}\")\n",
    "except Exception as e:\n",
    "    print(f\" Connection failed: {e}\")\n",
    "    print(\"Make sure Ollama is running with 'ollama serve'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00812bd",
   "metadata": {},
   "source": [
    "**Temperature Explained:**\n",
    "- 0.0 = Robot-like, same answer every time\n",
    "- 0.5 = Balanced  \n",
    "- 1.0 = Very creative, different answers each time\n",
    "- For math, we want consistency, so we use 0.0\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0bdaa4",
   "metadata": {},
   "source": [
    "## Step 6: Creating Tool Descriptions for Our AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83bcbe3",
   "metadata": {},
   "source": [
    "### Step 6a: Understanding the Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f70330a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Challenge:\n",
      "How do we tell our AI about available tools?\n",
      "Answer: We'll write descriptions it can understand!\n"
     ]
    }
   ],
   "source": [
    "# Our AI needs to know what tools are available\n",
    "# Since we can't use bind_tools(), we'll describe them in text\n",
    "\n",
    "print(\"The Challenge:\")\n",
    "print(\"How do we tell our AI about available tools?\")\n",
    "print(\"Answer: We'll write descriptions it can understand!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2d3ec4",
   "metadata": {},
   "source": [
    "### Step 6b: Creating Tool Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d82745c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Schema Created:\n",
      "\n",
      "                    Tool: add\n",
      "                    Description: Add two numbers together.\n",
      "                    Use when: you need to add two numbers\n",
      "                    \n",
      "\n",
      "                    Tool: subtract\n",
      "                    Description: Subtract x from y (y - x).\n",
      "                    Use when: you need to subtract one number from another\n",
      "                    \n",
      "\n",
      "                    Tool: multiply\n",
      "                    Description: Multiply two numbers together.\n",
      "                    Use when: you need to multiply two numbers\n",
      "                    \n",
      "\n",
      "                    Tool: exponentiate\n",
      "                    Description: Raise x to the power of y (x^y).\n",
      "                    Use when: you need to raise a number to a power\n",
      "                    \n",
      "\n",
      "                    Tool: final_answer\n",
      "                    Description: Provide the final answer to the user.\n",
      "\n",
      "    Args:\n",
      "        answer: The final answer in natural language\n",
      "        tools_used: List of tool names that were used\n",
      "                    Use when: you're ready to give the final answer to the user\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "def create_tool_schema() -> str:\n",
    "    \"\"\"Create a human-readable description of our tools.\"\"\"\n",
    "    \n",
    "    descriptions = []\n",
    "    \n",
    "    for tool in tools:\n",
    "        # Get information about each tool\n",
    "        tool_info = f\"\"\"\n",
    "                    Tool: {tool.name}\n",
    "                    Description: {tool.description}\n",
    "                    Use when: {_get_usage_hint(tool.name)}\n",
    "                    \"\"\"\n",
    "        descriptions.append(tool_info)\n",
    "    \n",
    "    return \"\\n\".join(descriptions)\n",
    "\n",
    "def _get_usage_hint(tool_name: str) -> str:\n",
    "    \"\"\"Provide hints about when to use each tool.\"\"\"\n",
    "    hints = {\n",
    "        \"add\": \"you need to add two numbers\",\n",
    "        \"subtract\": \"you need to subtract one number from another\",\n",
    "        \"multiply\": \"you need to multiply two numbers\", \n",
    "        \"exponentiate\": \"you need to raise a number to a power\",\n",
    "        \"final_answer\": \"you're ready to give the final answer to the user\"\n",
    "    }\n",
    "    return hints.get(tool_name, \"appropriate for this tool\")\n",
    "\n",
    "# Create our tool schema\n",
    "tool_schema = create_tool_schema()\n",
    "print(\"Tool Schema Created:\")\n",
    "print(tool_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ebde7b",
   "metadata": {},
   "source": [
    "## Step 7: Building the Communication System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f832fbe",
   "metadata": {},
   "source": [
    "\n",
    "### Step 7a: Understanding Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba20ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prompt is like giving instructions:\n",
      "\n",
      "You are a helpful assistant.\n",
      "When I ask a math question, use the add tool.\n",
      "Respond with: {\"tool\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}}\n",
      "\n",
      "\n",
      "The clearer the instructions, the better the AI performs!\n"
     ]
    }
   ],
   "source": [
    "# A prompt is like instructions you give to the AI\n",
    "# It needs to be very clear and specific\n",
    "\n",
    "sample_prompt = \"\"\"\n",
    "You are a helpful assistant.\n",
    "When I ask a math question, use the add tool.\n",
    "Respond with: {\"tool\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}}\n",
    "\"\"\"\n",
    "\n",
    "print(\"A prompt is like giving instructions:\")\n",
    "print(sample_prompt)\n",
    "print(\"\\nThe clearer the instructions, the better the AI performs!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3cc7d8",
   "metadata": {},
   "source": [
    "### Step 7b: Creating Our Agent Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29372104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent prompt template created!\n",
      "This tells our AI exactly how to behave and respond\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# This is our \"instruction manual\" for the AI\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ðŸ¤– You are a mathematical assistant with access to calculation tools.\n",
    "\n",
    "AVAILABLE TOOLS:\n",
    "{tool_schema}\n",
    "\n",
    " YOUR JOB:\n",
    "1. Analyze the user's math question\n",
    "2. Decide which tool to use\n",
    "3. Respond with ONLY valid JSON in this format:\n",
    "\n",
    "{{\n",
    "    \"thinking\": \"What calculation do I need to do?\",\n",
    "    \"tool_name\": \"name_of_tool_to_use\", \n",
    "    \"parameters\": {{\"param1\": value1, \"param2\": value2}}\n",
    "}}\n",
    "\n",
    "PREVIOUS WORK (if any):\n",
    "{scratchpad}\n",
    "\n",
    "IMPORTANT: \n",
    "- Always respond with valid JSON only\n",
    "- Use final_answer when you have the complete answer\n",
    "- Think step by step for complex problems\"\"\"),\n",
    "    \n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "print(\"Agent prompt template created!\")\n",
    "print(\"This tells our AI exactly how to behave and respond\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ecc644",
   "metadata": {},
   "source": [
    "**Breaking down the prompt:**\n",
    "- **System message**: The \"rules\" and instructions\n",
    "- **Tool schema**: Description of available tools (filled in later)\n",
    "- **Scratchpad**: Previous calculations (for multi-step problems)\n",
    "- **JSON format**: Exact structure we expect back\n",
    "- **Human message**: The user's actual question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b22a60",
   "metadata": {},
   "source": [
    "## Step 8: Creating the JSON Response Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af62d1",
   "metadata": {},
   "source": [
    "### Step 8a: Understanding the Parsing Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30741cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to handle different response formats:\n",
      "1. {\"tool_name\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}}\n",
      "2. I need to add these numbers: {\"tool_name\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}}\n",
      "3. Let me calculate:\n",
      "{\"tool_name\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}}\n",
      "There you go!\n"
     ]
    }
   ],
   "source": [
    "# The AI might respond with extra text around the JSON\n",
    "# We need to find and extract just the JSON part\n",
    "\n",
    "examples = [\n",
    "    '{\"tool_name\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}}',\n",
    "    'I need to add these numbers: {\"tool_name\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}}',\n",
    "    'Let me calculate:\\n{\"tool_name\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}}\\nThere you go!'\n",
    "]\n",
    "\n",
    "print(\"We need to handle different response formats:\")\n",
    "for i, example in enumerate(examples, 1):\n",
    "    print(f\"{i}. {example}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fdc1d0",
   "metadata": {},
   "source": [
    "### Step 8b: Building a Simple JSON Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86c5f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The answer is: {\"tool_name\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}} - hope this helps!\n",
      "Found JSON: {\"tool_name\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def find_json_in_text(text: str) -> str:\n",
    "    \"\"\"Find JSON object in text using pattern matching.\"\"\"\n",
    "    \n",
    "    # Look for text that starts with { and ends with }\n",
    "    json_pattern = r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}'\n",
    "    \n",
    "    matches = re.findall(json_pattern, text)\n",
    "    \n",
    "    if matches:\n",
    "        return matches[0]  # Return the first JSON-like string found\n",
    "    else:\n",
    "        return text.strip()  # If no pattern found, return the whole text\n",
    "\n",
    "# Test our JSON finder\n",
    "test_text = 'The answer is: {\"tool_name\": \"add\", \"parameters\": {\"x\": 5, \"y\": 3}} - hope this helps!'\n",
    "found_json = find_json_in_text(test_text)\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"Found JSON: {found_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c453873f",
   "metadata": {},
   "source": [
    "\n",
    "### Step 8c: Building the Complete Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c230e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing response: {\"thinking\": \"I need to add\", \"tool_name\": \"add\", \"parameters\": {\"x\": 10, \"y\": 5}}...\n",
      "Extracted JSON: {\"thinking\": \"I need to add\", \"tool_name\": \"add\", \"parameters\": {\"x\": 10, \"y\": 5}}\n",
      "Successfully parsed JSON\n",
      "Final parsed result: {'thinking': 'I need to add', 'tool_name': 'add', 'parameters': {'x': 10, 'y': 5}}\n"
     ]
    }
   ],
   "source": [
    "def parse_ai_response(response: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse the AI's response to extract tool call information.\"\"\"\n",
    "    \n",
    "    print(f\"Parsing response: {response[:100]}...\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Find JSON in the response\n",
    "        json_text = find_json_in_text(response)\n",
    "        print(f\"Extracted JSON: {json_text}\")\n",
    "        \n",
    "        # Step 2: Parse the JSON\n",
    "        parsed = json.loads(json_text)\n",
    "        print(f\"Successfully parsed JSON\")\n",
    "        \n",
    "        # Step 3: Validate required fields\n",
    "        required_fields = [\"tool_name\", \"parameters\"]\n",
    "        for field in required_fields:\n",
    "            if field not in parsed:\n",
    "                print(f\"Missing required field: {field}\")\n",
    "                parsed[field] = \"final_answer\" if field == \"tool_name\" else {}\n",
    "        \n",
    "        return parsed\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing failed: {e}\")\n",
    "        \n",
    "        # Return a safe default\n",
    "        return {\n",
    "            \"thinking\": \"Failed to parse response\",\n",
    "            \"tool_name\": \"final_answer\",\n",
    "            \"parameters\": {\n",
    "                \"answer\": \"I'm sorry, I had trouble understanding the request.\",\n",
    "                \"tools_used\": []\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Test the parser\n",
    "test_response = '{\"thinking\": \"I need to add\", \"tool_name\": \"add\", \"parameters\": {\"x\": 10, \"y\": 5}}'\n",
    "parsed = parse_ai_response(test_response)\n",
    "print(f\"Final parsed result: {parsed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7a42b",
   "metadata": {},
   "source": [
    "**What this parser does:**\n",
    "1. **Finds JSON**: Uses regex to locate JSON in messy text\n",
    "2. **Parses safely**: Handles errors gracefully\n",
    "3. **Validates**: Checks that required fields exist\n",
    "4. **Provides fallback**: Returns safe default if parsing fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c5295",
   "metadata": {},
   "source": [
    "## Step 9: Building the Tool Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2288942b",
   "metadata": {},
   "source": [
    "### Step 9a: Understanding Tool Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "278c1240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Tool execution process:\n",
      "1. Get tool name from parsed JSON\n",
      "2. Look up the actual function\n",
      "3. Get parameters from parsed JSON\n",
      "4. Call the function with those parameters\n",
      "5. Handle any errors that might occur\n"
     ]
    }
   ],
   "source": [
    "# Once we know which tool to use, we need to actually run it\n",
    "# This involves looking up the function and calling it with the right parameters\n",
    "\n",
    "print(\"ðŸ”§ Tool execution process:\")\n",
    "print(\"1. Get tool name from parsed JSON\")\n",
    "print(\"2. Look up the actual function\") \n",
    "print(\"3. Get parameters from parsed JSON\")\n",
    "print(\"4. Call the function with those parameters\")\n",
    "print(\"5. Handle any errors that might occur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008906c",
   "metadata": {},
   "source": [
    "### Step 9b: Creating a Safe Tool Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "357f54b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing tool: add\n",
      "Parameters: {'x': 10, 'y': 5}\n",
      "Found tool function: add\n",
      "Tool executed successfully\n",
      "Test result: 15\n"
     ]
    }
   ],
   "source": [
    "def execute_tool_safely(tool_name: str, parameters: Dict[str, Any]) -> Any:\n",
    "    \"\"\"Safely execute a tool with error handling.\"\"\"\n",
    "    \n",
    "    print(f\"Executing tool: {tool_name}\")\n",
    "    print(f\"Parameters: {parameters}\")\n",
    "    \n",
    "    # Step 1: Check if tool exists\n",
    "    if tool_name not in name2tool:\n",
    "        error_msg = f\"Tool '{tool_name}' not found!\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    \n",
    "    try:\n",
    "        # Step 2: Get the actual function\n",
    "        tool_function = name2tool[tool_name]\n",
    "        print(f\"Found tool function: {tool_function.__name__}\")\n",
    "        \n",
    "        # Step 3: Execute the function\n",
    "        result = tool_function(**parameters)\n",
    "        print(f\"Tool executed successfully\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except TypeError as e:\n",
    "        # This happens when parameters don't match the function signature\n",
    "        error_msg = f\"Parameter error for {tool_name}: {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "        \n",
    "    except Exception as e:\n",
    "        # This catches any other unexpected errors\n",
    "        error_msg = f\"Execution error for {tool_name}: {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "# Test the executor\n",
    "test_result = execute_tool_safely(\"add\", {\"x\": 10, \"y\": 5})\n",
    "print(f\"Test result: {test_result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a6001c",
   "metadata": {},
   "source": [
    "**Why all this error handling?**\n",
    "- The AI might request a tool that doesn't exist\n",
    "- The AI might provide wrong parameter names\n",
    "- The AI might provide wrong parameter types\n",
    "- We want our agent to be robust and not crash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c9ffd",
   "metadata": {},
   "source": [
    "## Step 10: Building the Agent Brain (The Main Loop) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa570a7",
   "metadata": {},
   "source": [
    "### Step 10a: Understanding the Agent Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50ca43ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ The Agent Loop:\n",
      "â”Œâ”€ User asks question\n",
      "â”‚  â†“\n",
      "â”œâ”€ Agent thinks about what to do\n",
      "â”‚  â†“\n",
      "â”œâ”€ Agent uses a tool\n",
      "â”‚  â†“\n",
      "â”œâ”€ Agent sees result\n",
      "â”‚  â†“\n",
      "â”œâ”€ Done? â†’ Give final answer\n",
      "â”‚  â†“\n",
      "â””â”€ Not done? â†’ Think about next step (repeat)\n"
     ]
    }
   ],
   "source": [
    "# Our agent needs to:\n",
    "# 1. Take a user question\n",
    "# 2. Think about what tool to use\n",
    "# 3. Use that tool\n",
    "# 4. Look at the result\n",
    "# 5. Decide if it's done or needs more tools\n",
    "# 6. Repeat until it has a final answer\n",
    "\n",
    "print(\"ðŸ”„ The Agent Loop:\")\n",
    "print(\"â”Œâ”€ User asks question\")\n",
    "print(\"â”‚  â†“\")\n",
    "print(\"â”œâ”€ Agent thinks about what to do\") \n",
    "print(\"â”‚  â†“\")\n",
    "print(\"â”œâ”€ Agent uses a tool\")\n",
    "print(\"â”‚  â†“\")\n",
    "print(\"â”œâ”€ Agent sees result\")\n",
    "print(\"â”‚  â†“\")\n",
    "print(\"â”œâ”€ Done? â†’ Give final answer\")\n",
    "print(\"â”‚  â†“\")\n",
    "print(\"â””â”€ Not done? â†’ Think about next step (repeat)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceba65e",
   "metadata": {},
   "source": [
    "### Step 10b: Building the Simple Agent Class Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00a25230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent initialized with max 3 steps\n",
      "\n",
      "Working on: What is 2 + 2?\n",
      "I'm ready to solve problems!\n"
     ]
    }
   ],
   "source": [
    "class SimpleOllamaAgent:\n",
    "    \"\"\"A simple agent that can use tools to solve math problems.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_steps: int = 5):\n",
    "        \"\"\"Initialize the agent.\n",
    "        \n",
    "        Args:\n",
    "            max_steps: Maximum number of tool uses to prevent infinite loops\n",
    "        \"\"\"\n",
    "        self.max_steps = max_steps\n",
    "        self.llm = llm  # Our Ollama connection\n",
    "        \n",
    "        print(f\"Agent initialized with max {max_steps} steps\")\n",
    "    \n",
    "    def solve(self, question: str) -> str:\n",
    "        \"\"\"Solve a math problem step by step.\"\"\"\n",
    "        print(f\"\\nWorking on: {question}\")\n",
    "        return \"I'm ready to solve problems!\"\n",
    "\n",
    "# Test creating an agent\n",
    "agent = SimpleOllamaAgent(max_steps=3)\n",
    "test_solve = agent.solve(\"What is 2 + 2?\")\n",
    "print(test_solve)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd891488",
   "metadata": {},
   "source": [
    "### Step 10c: Adding the Scratchpad System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb4775dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted scratchpad:\n",
      "Step 1: Used add(5, 3) = 8\n",
      "Step 2: Used multiply(8, 2) = 16\n"
     ]
    }
   ],
   "source": [
    "def format_scratchpad(steps: List[str]) -> str:\n",
    "    \"\"\"Format previous steps for display to the AI.\"\"\"\n",
    "    \n",
    "    if not steps:\n",
    "        return \"No previous calculations.\"\n",
    "    \n",
    "    formatted_steps = []\n",
    "    for i, step in enumerate(steps, 1):\n",
    "        formatted_steps.append(f\"Step {i}: {step}\")\n",
    "    \n",
    "    return \"\\n\".join(formatted_steps)\n",
    "\n",
    "# Test the scratchpad formatter\n",
    "test_steps = [\n",
    "    \"Used add(5, 3) = 8\",\n",
    "    \"Used multiply(8, 2) = 16\"\n",
    "]\n",
    "\n",
    "formatted = format_scratchpad(test_steps)\n",
    "print(\"Formatted scratchpad:\")\n",
    "print(formatted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e4567",
   "metadata": {},
   "source": [
    "**What's a scratchpad?**\n",
    "- It's like showing your work in math class\n",
    "- Keeps track of what the agent has already calculated\n",
    "- Helps the agent build on previous results\n",
    "- Makes the thinking process visible\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b0b73",
   "metadata": {},
   "source": [
    "\n",
    "### Step 10d: Implementing the Main Solve Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f6211e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleOllamaAgent:\n",
    "    \"\"\"A simple agent that can use tools to solve math problems.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_steps: int = 5):\n",
    "        self.max_steps = max_steps\n",
    "        self.llm = llm\n",
    "        self.scratchpad = []  # Keep track of what we've done\n",
    "        \n",
    "    def solve(self, question: str) -> str:\n",
    "        \"\"\"Solve a math problem step by step.\"\"\"\n",
    "        \n",
    "        print(f\"\\n Working on: {question}\")\n",
    "        self.scratchpad = []  # Start fresh for each question\n",
    "        \n",
    "        for step_number in range(1, self.max_steps + 1):\n",
    "            print(f\"\\n--- Step {step_number} ---\")\n",
    "            \n",
    "            # Step 1: Create the prompt with current context\n",
    "            formatted_scratchpad = format_scratchpad(self.scratchpad)\n",
    "            \n",
    "            full_prompt = agent_prompt.format(\n",
    "                tool_schema=tool_schema,\n",
    "                scratchpad=formatted_scratchpad,\n",
    "                input=question\n",
    "            )\n",
    "            \n",
    "            print(\"Asking AI what to do next...\")\n",
    "            \n",
    "            # Step 2: Get AI's response\n",
    "            ai_response = self.llm.invoke(full_prompt)\n",
    "            print(f\"AI says: {ai_response}\")\n",
    "            \n",
    "            # Step 3: Parse the response\n",
    "            parsed = parse_ai_response(ai_response)\n",
    "            \n",
    "            tool_name = parsed[\"tool_name\"]\n",
    "            parameters = parsed[\"parameters\"]\n",
    "            thinking = parsed.get(\"thinking\", \"No reasoning provided\")\n",
    "            \n",
    "            print(f\"AI is thinking: {thinking}\")\n",
    "            print(f\"Wants to use: {tool_name}({parameters})\")\n",
    "            \n",
    "            # Step 4: Execute the tool\n",
    "            result = execute_tool_safely(tool_name, parameters)\n",
    "            \n",
    "            # Normalize result summary for the scratchpad\n",
    "            step_summary = f\"Used {tool_name}({parameters}) â†’ {result}\"\n",
    "            self.scratchpad.append(step_summary)\n",
    "            \n",
    "            # If the tool returned the special final_answer structure, finish\n",
    "            if tool_name == \"final_answer\":\n",
    "                # result is expected to be a dict like {\"answer\": \"...\", \"tools_used\": [...]}\n",
    "                if isinstance(result, dict) and \"answer\" in result:\n",
    "                    print(f\"Done! Final answer: {result['answer']}\")\n",
    "                    return result[\"answer\"]\n",
    "                else:\n",
    "                    # Unexpected shape; return a safe message\n",
    "                    return \"Agent returned final_answer but result format was unexpected.\"\n",
    "            \n",
    "            # Automatic finalize: if a math tool returned a numeric result, produce the final answer\n",
    "            # This avoids asking the model to call final_answer for simple single-step math\n",
    "            if isinstance(result, (int, float)):\n",
    "                answer_text = str(result)\n",
    "                tools_used = [tool_name]\n",
    "                # Call the final_answer tool directly to keep consistent output format\n",
    "                final_result = name2tool[\"final_answer\"](answer=answer_text, tools_used=tools_used)\n",
    "                if isinstance(final_result, dict) and \"answer\" in final_result:\n",
    "                    print(f\"Auto-finalized. Final answer: {final_result['answer']}\")\n",
    "                    return final_result[\"answer\"]\n",
    "                else:\n",
    "                    return answer_text\n",
    "        \n",
    "        # If we used all steps without finishing\n",
    "        return \"I couldn't solve this within the allowed steps. Please try a simpler question.\"\n",
    "\n",
    "\n",
    "# Create and test our agent\n",
    "agent = SimpleOllamaAgent(max_steps=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "503a3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ast\n",
    "import operator as _op\n",
    "\n",
    "# safe eval helper for simple numeric expressions\n",
    "_allowed_operators = {\n",
    "    ast.Add: _op.add,\n",
    "    ast.Sub: _op.sub,\n",
    "    ast.Mult: _op.mul,\n",
    "    ast.Div: _op.truediv,\n",
    "    ast.Pow: _op.pow,\n",
    "    ast.Mod: _op.mod,\n",
    "    ast.USub: _op.neg,\n",
    "    ast.UAdd: _op.pos,\n",
    "}\n",
    "\n",
    "def _eval_node(node):\n",
    "    if isinstance(node, ast.Constant):  # Python 3.8+: ast.Num merged into Constant\n",
    "        if isinstance(node.value, (int, float)):\n",
    "            return node.value\n",
    "        raise ValueError(\"Only numeric constants allowed\")\n",
    "    if isinstance(node, ast.Num):  # fallback for older ast\n",
    "        return node.n\n",
    "    if isinstance(node, ast.BinOp):\n",
    "        left = _eval_node(node.left)\n",
    "        right = _eval_node(node.right)\n",
    "        op_type = type(node.op)\n",
    "        if op_type in _allowed_operators:\n",
    "            return _allowed_operators[op_type](left, right)\n",
    "        raise ValueError(f\"Operator {op_type} not allowed\")\n",
    "    if isinstance(node, ast.UnaryOp):\n",
    "        operand = _eval_node(node.operand)\n",
    "        op_type = type(node.op)\n",
    "        if op_type in _allowed_operators:\n",
    "            return _allowed_operators[op_type](operand)\n",
    "        raise ValueError(f\"Unary operator {op_type} not allowed\")\n",
    "    raise ValueError(f\"Unsupported AST node: {type(node)}\")\n",
    "\n",
    "def safe_eval_expr(expr: str) -> float:\n",
    "    \"\"\"Safely evaluate a simple arithmetic expression and return numeric result.\"\"\"\n",
    "    expr = expr.strip()\n",
    "    if expr == \"\":\n",
    "        raise ValueError(\"Empty expression\")\n",
    "    # allow parentheses, numbers, and basic operators\n",
    "    try:\n",
    "        node = ast.parse(expr, mode=\"eval\").body\n",
    "        return _eval_node(node)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Unsafe or invalid expression: {expr} ({e})\")\n",
    "\n",
    "def _coerce_value(val):\n",
    "    \"\"\"Coerce individual parameter value to numeric if it looks like an expression or numeric string.\"\"\"\n",
    "    # If already numeric, return as-is\n",
    "    if isinstance(val, (int, float)):\n",
    "        return val\n",
    "    # If it's a boolean or None, keep as-is\n",
    "    if isinstance(val, (bool, type(None))):\n",
    "        return val\n",
    "    # If it's a dict or list, coerce recursively\n",
    "    if isinstance(val, dict):\n",
    "        return {k: _coerce_value(v) for k, v in val.items()}\n",
    "    if isinstance(val, list):\n",
    "        return [_coerce_value(v) for v in val]\n",
    "    # If string, try to convert to int/float first, then try safe eval for expressions like \"(4 + 6)\"\n",
    "    if isinstance(val, str):\n",
    "        s = val.strip()\n",
    "        # remove surrounding quotes if present\n",
    "        if (s.startswith(\"'\") and s.endswith(\"'\")) or (s.startswith('\"') and s.endswith('\"')):\n",
    "            s = s[1:-1].strip()\n",
    "        # try int\n",
    "        try:\n",
    "            return int(s)\n",
    "        except Exception:\n",
    "            pass\n",
    "        # try float\n",
    "        try:\n",
    "            return float(s)\n",
    "        except Exception:\n",
    "            pass\n",
    "        # try safe arithmetic eval if it contains digits and arithmetic chars\n",
    "        if any(ch.isdigit() for ch in s) and any(ch in \"+-*/%^() \" for ch in s):\n",
    "            # replace ^ with ** if user used caret\n",
    "            s2 = s.replace(\"^\", \"**\")\n",
    "            try:\n",
    "                return safe_eval_expr(s2)\n",
    "            except Exception:\n",
    "                pass\n",
    "    # fallback: return original\n",
    "    return val\n",
    "\n",
    "def execute_tool_safely(tool_name: str, parameters: Dict[str, Any]) -> Any:\n",
    "    \"\"\"Safely execute a tool with error handling and coerce parameter types.\"\"\"\n",
    "    \n",
    "    print(f\"Executing tool: {tool_name}\")\n",
    "    print(f\"Parameters: {parameters}\")\n",
    "    \n",
    "    # Step 1: Check if tool exists\n",
    "    if tool_name not in name2tool:\n",
    "        error_msg = f\"Tool '{tool_name}' not found!\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    \n",
    "    try:\n",
    "        # Step 2: Get the actual function\n",
    "        tool_function = name2tool[tool_name]\n",
    "        print(f\"Found tool function: {tool_function.__name__}\")\n",
    "        \n",
    "        # Coerce parameter values to numeric types where appropriate\n",
    "        coerced_params = {}\n",
    "        if isinstance(parameters, dict):\n",
    "            for k, v in parameters.items():\n",
    "                new_v = _coerce_value(v)\n",
    "                if new_v != v:\n",
    "                    print(f\"Coerced parameter '{k}': {v} -> {new_v}\")\n",
    "                coerced_params[k] = new_v\n",
    "        else:\n",
    "            # If parameters is not a dict (unexpected), attempt to coerce whole object\n",
    "            coerced_params = _coerce_value(parameters)\n",
    "        \n",
    "        # Step 3: Execute the function\n",
    "        # If tool expects kwargs and we have a dict, pass as kwargs\n",
    "        if isinstance(coerced_params, dict):\n",
    "            result = tool_function(**coerced_params)\n",
    "        else:\n",
    "            # Otherwise attempt single-argument call\n",
    "            result = tool_function(coerced_params)\n",
    "        print(f\"Tool executed successfully\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except TypeError as e:\n",
    "        # This happens when parameters don't match the function signature\n",
    "        error_msg = f\"Parameter error for {tool_name}: {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "        \n",
    "    except Exception as e:\n",
    "        # This catches any other unexpected errors\n",
    "        error_msg = f\"Execution error for {tool_name}: {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e34862",
   "metadata": {},
   "source": [
    "## Step 11: Testing Our Agent Step by Step "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5c3b5d",
   "metadata": {},
   "source": [
    "### Step 11a: Simple Addition Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bc1a975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 1: Simple Addition\n",
      "========================================\n",
      "\n",
      " Working on: What is 7 + 3?\n",
      "\n",
      "--- Step 1 ---\n",
      "Asking AI what to do next...\n",
      "AI says: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"add\",\n",
      "    \"parameters\": {\"x\": 7, \"y\": 3}\n",
      "}\n",
      "Parsing response: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"add\",\n",
      "    \"parameters\": {\"x...\n",
      "Extracted JSON: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"add\",\n",
      "    \"parameters\": {\"x\": 7, \"y\": 3}\n",
      "}\n",
      "Successfully parsed JSON\n",
      "AI is thinking: What calculation do I need to do?\n",
      "Wants to use: add({'x': 7, 'y': 3})\n",
      "Executing tool: add\n",
      "Parameters: {'x': 7, 'y': 3}\n",
      "Found tool function: add\n",
      "Tool executed successfully\n",
      "Final Answer: 10\n",
      "Tools Used: ['add']\n",
      "Auto-finalized. Final answer: 10\n",
      "\n",
      "Final Result: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST 1: Simple Addition\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "result1 = agent.solve(\"What is 7 + 3?\")\n",
    "print(f\"\\nFinal Result: {result1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32e917",
   "metadata": {},
   "source": [
    "### Step 11b: Two-Step Calculation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "982c6a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST 2: Two-Step Calculation\n",
      "========================================\n",
      "\n",
      " Working on: What is (4 + 6) multiplied by 2?\n",
      "\n",
      "--- Step 1 ---\n",
      "Asking AI what to do next...\n",
      "AI says: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"multiply\",\n",
      "    \"parameters\": {\"x\": \"(4 + 6)\", \"y\": \"2\"}\n",
      "}\n",
      "Parsing response: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"multiply\",\n",
      "    \"parameters\"...\n",
      "Extracted JSON: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"multiply\",\n",
      "    \"parameters\": {\"x\": \"(4 + 6)\", \"y\": \"2\"}\n",
      "}\n",
      "Successfully parsed JSON\n",
      "AI is thinking: What calculation do I need to do?\n",
      "Wants to use: multiply({'x': '(4 + 6)', 'y': '2'})\n",
      "Executing tool: multiply\n",
      "Parameters: {'x': '(4 + 6)', 'y': '2'}\n",
      "Found tool function: multiply\n",
      "Coerced parameter 'x': (4 + 6) -> 10\n",
      "Coerced parameter 'y': 2 -> 2\n",
      " Multiplying 10 Ã— 2 = 20\n",
      "Tool executed successfully\n",
      "Final Answer: 20\n",
      "Tools Used: ['multiply']\n",
      "Auto-finalized. Final answer: 20\n",
      "\n",
      "Final Result: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USERAS\\AppData\\Local\\Temp\\ipykernel_9500\\3882710328.py:21: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # fallback for older ast\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTEST 2: Two-Step Calculation\")  \n",
    "print(\"=\" * 40)\n",
    "\n",
    "result2 = agent.solve(\"What is (4 + 6) multiplied by 2?\")\n",
    "print(f\"\\nFinal Result: {result2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46941c55",
   "metadata": {},
   "source": [
    "### Step 11c: Power/Exponent Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7715b50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\TEST 3: Exponentiation\n",
      "========================================\n",
      "\n",
      " Working on: What is 3 to the power of 4?\n",
      "\n",
      "--- Step 1 ---\n",
      "Asking AI what to do next...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\USERAS\\AppData\\Local\\Temp\\ipykernel_9500\\3121182763.py:1: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  print(\"\\TEST 3: Exponentiation\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI says: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"exponentiate\",\n",
      "    \"parameters\": {\"x\": 3, \"y\": 4}\n",
      "}\n",
      "Parsing response: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"exponentiate\",\n",
      "    \"paramet...\n",
      "Extracted JSON: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"exponentiate\",\n",
      "    \"parameters\": {\"x\": 3, \"y\": 4}\n",
      "}\n",
      "Successfully parsed JSON\n",
      "AI is thinking: What calculation do I need to do?\n",
      "Wants to use: exponentiate({'x': 3, 'y': 4})\n",
      "Executing tool: exponentiate\n",
      "Parameters: {'x': 3, 'y': 4}\n",
      "Found tool function: exponentiate\n",
      " Calculating 3^4 = 81\n",
      "Tool executed successfully\n",
      "Final Answer: 81\n",
      "Tools Used: ['exponentiate']\n",
      "Auto-finalized. Final answer: 81\n",
      "\n",
      "Final Result: 81\n"
     ]
    }
   ],
   "source": [
    "print(\"\\TEST 3: Exponentiation\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "result3 = agent.solve(\"What is 3 to the power of 4?\")\n",
    "print(f\"\\nFinal Result: {result3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd57d8",
   "metadata": {},
   "source": [
    "**What to look for in the output:**\n",
    "- Each step should be clearly numbered\n",
    "- You should see the AI's thinking process\n",
    "- Tool executions should show parameters and results\n",
    "- The scratchpad should build up over multiple steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed5ca2",
   "metadata": {},
   "source": [
    "## Step 12: Adding Memory for Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d2c42",
   "metadata": {},
   "source": [
    "### Step 12a: Understanding Conversation Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8a7fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryOllamaAgent(SimpleOllamaAgent):\n",
    "    \"\"\"An agent with conversation memory.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_steps: int = 5):\n",
    "        super().__init__(max_steps)\n",
    "        self.conversation_history = []  # Remember past conversations\n",
    "        \n",
    "    def solve(self, question: str) -> str:\n",
    "        \"\"\"Solve a problem and remember the conversation.\n",
    "        \n",
    "        Includes recent conversation context in the prompt and saves final answers\n",
    "        (whether produced by final_answer tool or auto-finalized numeric results).\n",
    "        \"\"\"\n",
    "        print(f\"\\nWorking on: {question}\")\n",
    "        \n",
    "        # Show conversation history if it exists\n",
    "        if self.conversation_history:\n",
    "            print(\"Conversation history:\")\n",
    "            for i, (q, a) in enumerate(self.conversation_history[-3:], 1):  # Show last 3\n",
    "                print(f\"  {i}. Q: {q}\")\n",
    "                print(f\"     A: {a}\")\n",
    "        \n",
    "        # Solve the problem (similar loop as SimpleOllamaAgent but include context)\n",
    "        self.scratchpad = []\n",
    "        \n",
    "        for step_number in range(1, self.max_steps + 1):\n",
    "            print(f\"\\n--- Step {step_number} ---\")\n",
    "            \n",
    "            formatted_scratchpad = format_scratchpad(self.scratchpad)\n",
    "            context = self._build_context()\n",
    "            \n",
    "            full_prompt = agent_prompt.format(\n",
    "                tool_schema=tool_schema,\n",
    "                scratchpad=formatted_scratchpad + \"\\n\\n\" + context,\n",
    "                input=question\n",
    "            )\n",
    "            \n",
    "            print(\"Asking AI what to do next...\")\n",
    "            ai_response = self.llm.invoke(full_prompt)\n",
    "            print(f\"AI says: {ai_response}\")\n",
    "            \n",
    "            parsed = parse_ai_response(ai_response)\n",
    "            tool_name = parsed[\"tool_name\"]\n",
    "            parameters = parsed[\"parameters\"]\n",
    "            thinking = parsed.get(\"thinking\", \"No reasoning provided\")\n",
    "            \n",
    "            print(f\" AI is thinking: {thinking}\")\n",
    "            print(f\" Wants to use: {tool_name}({parameters})\")\n",
    "            \n",
    "            result = execute_tool_safely(tool_name, parameters)\n",
    "            step_summary = f\"Used {tool_name}({parameters}) â†’ {result}\"\n",
    "            self.scratchpad.append(step_summary)\n",
    "            \n",
    "            # If the tool returned the special final_answer structure, finish and save\n",
    "            if tool_name == \"final_answer\":\n",
    "                if isinstance(result, dict) and \"answer\" in result:\n",
    "                    final_answer = result[\"answer\"]\n",
    "                else:\n",
    "                    final_answer = \"Agent returned final_answer but result format was unexpected.\"\n",
    "                # Save to conversation history\n",
    "                self.conversation_history.append((question, final_answer))\n",
    "                print(f\" Done! Final answer: {final_answer}\")\n",
    "                return final_answer\n",
    "            \n",
    "            # Auto-finalize numeric results (same behavior as SimpleOllamaAgent)\n",
    "            if isinstance(result, (int, float)):\n",
    "                answer_text = str(result)\n",
    "                tools_used = [tool_name]\n",
    "                final_result = name2tool[\"final_answer\"](answer=answer_text, tools_used=tools_used)\n",
    "                if isinstance(final_result, dict) and \"answer\" in final_result:\n",
    "                    final_answer = final_result[\"answer\"]\n",
    "                else:\n",
    "                    final_answer = answer_text\n",
    "                # Save to conversation history\n",
    "                self.conversation_history.append((question, final_answer))\n",
    "                print(f\"Auto-finalized. Final answer: {final_answer}\")\n",
    "                return final_answer\n",
    "        \n",
    "        return \"I couldn't solve this within the allowed steps.\"\n",
    "    \n",
    "    def _build_context(self) -> str:\n",
    "        \"\"\"Build context from recent conversations.\"\"\"\n",
    "        if not self.conversation_history:\n",
    "            return \"No previous conversation.\"\n",
    "        \n",
    "        context_parts = [\" Recent conversation:\"]\n",
    "        for q, a in self.conversation_history[-2:]:  # Last 2 conversations\n",
    "            context_parts.append(f\"Q: {q}\")\n",
    "            context_parts.append(f\"A: {a}\")\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "\n",
    "# Create the new agent with memory\n",
    "memory_agent = MemoryOllamaAgent(max_steps=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "584f560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_agent = MemoryOllamaAgent(max_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c060b46",
   "metadata": {},
   "source": [
    "### Step 12c: Testing Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d6e1e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 4: Memory Test\n",
      "========================================\n",
      "\n",
      "Working on: What is 5 + 10?\n",
      "\n",
      "--- Step 1 ---\n",
      "Asking AI what to do next...\n",
      "AI says: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"add\",\n",
      "    \"parameters\": {\"x\": 5, \"y\": 10}\n",
      "}\n",
      "Parsing response: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"add\",\n",
      "    \"parameters\": {\"x...\n",
      "Extracted JSON: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"add\",\n",
      "    \"parameters\": {\"x\": 5, \"y\": 10}\n",
      "}\n",
      "Successfully parsed JSON\n",
      " AI is thinking: What calculation do I need to do?\n",
      " Wants to use: add({'x': 5, 'y': 10})\n",
      "Executing tool: add\n",
      "Parameters: {'x': 5, 'y': 10}\n",
      "Found tool function: add\n",
      "Tool executed successfully\n",
      "Final Answer: 15\n",
      "Tools Used: ['add']\n",
      "Auto-finalized. Final answer: 15\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Working on: Now multiply that result by 2\n",
      "Conversation history:\n",
      "  1. Q: What is 5 + 10?\n",
      "     A: 15\n",
      "\n",
      "--- Step 1 ---\n",
      "Asking AI what to do next...\n",
      "AI says: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"multiply\",\n",
      "    \"parameters\": {\"x\": 15, \"y\": 2}\n",
      "}\n",
      "Parsing response: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"multiply\",\n",
      "    \"parameters\"...\n",
      "Extracted JSON: {\n",
      "    \"thinking\": \"What calculation do I need to do?\",\n",
      "    \"tool_name\": \"multiply\",\n",
      "    \"parameters\": {\"x\": 15, \"y\": 2}\n",
      "}\n",
      "Successfully parsed JSON\n",
      " AI is thinking: What calculation do I need to do?\n",
      " Wants to use: multiply({'x': 15, 'y': 2})\n",
      "Executing tool: multiply\n",
      "Parameters: {'x': 15, 'y': 2}\n",
      "Found tool function: multiply\n",
      " Multiplying 15 Ã— 2 = 30\n",
      "Tool executed successfully\n",
      "Final Answer: 30\n",
      "Tools Used: ['multiply']\n",
      "Auto-finalized. Final answer: 30\n",
      "\n",
      "Conversation History Length: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST 4: Memory Test\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# First question\n",
    "result1 = memory_agent.solve(\"What is 5 + 10?\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "\n",
    "# Second question that might reference the first\n",
    "result2 = memory_agent.solve(\"Now multiply that result by 2\")\n",
    "\n",
    "print(f\"\\nConversation History Length: {len(memory_agent.conversation_history)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langChain-v0.3 (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
