{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain Essentials Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith Starter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith is a built-in observability service and platform that integrates _very easily_ with LangChain. You don't _need_ to use LangSmith for this course, but it can be very helpful in understanding what is happening, _and_ we recommend using it beyond this course for general development with LangChain — with all of that in mind we would recommend spending a little bit of time to get familiar with LangSmith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "  langchain-core \\\n",
    "  langchain-openai\\\n",
    "  langchain-community \\\n",
    "  langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith does require an API key, but it comes with a generous free tier. You can sign up an account and get your API key [here](https://smith.langchain.com).\n",
    "\n",
    "When using LangSmith, we need to setup our environment variables _and_ provide our API key, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from constant import langSmith_key  \n",
    "from constant import gemini_key     \n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = langSmith_key\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "\n",
    "# customize your project name\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"aurelioai-langchain-course-langsmith-gemini\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, this is all we need to start seeing logs and traces in the [LangSmith UI](https://smith.langchain.com). By default, LangChain will trace LLM calls, chains, etc. We'll take a look at a quick example of this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Tracing\n",
    "\n",
    "As mentioned, LangSmith traces a lot of data without us needing to do anything. Let's see how that looks. We'll start by initializing our LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangSmith + Gemini setup complete!\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = gemini_key\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "gemini_model = \"gemini-1.5-flash\"  \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=gemini_model, temperature=0.0)      \n",
    "creative_llm = ChatGoogleGenerativeAI(model=gemini_model, temperature=0.9)  \n",
    "\n",
    "print(\"LangSmith + Gemini setup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "response = llm.invoke(\"hello\")\n",
    "wrapped = textwrap.fill(response.content, width=80)\n",
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this we should see that a new project (`aurelioai-langchain-course-langsmith-openai`) has been created in the LangSmith UI. Inside that project, we should see the trace from our LLM call:\n",
    "\n",
    "\n",
    "![LangSmith LLM Trace](../assets/langsmith_dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, LangSmith will capture plenty — however, it won't capture functions from outside of LangChain. Let's see how we can trace those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing Non-LangChain Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LangSmith can trace functions that are not part of LangChain, we just need to add the `@traceable` decorator. Let's try this for a few simple functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "@traceable\n",
    "def generate_random_number():\n",
    "    return random.randint(0, 100)\n",
    "\n",
    "@traceable\n",
    "def generate_string_delay(input_str: str):\n",
    "    number = random.randint(1, 5)\n",
    "    time.sleep(number)\n",
    "    return f\"{input_str} ({number})\"\n",
    "\n",
    "@traceable\n",
    "def random_error():\n",
    "    number = random.randint(0, 1)\n",
    "    if number == 0:\n",
    "        raise ValueError(\"Random error\")\n",
    "    else:\n",
    "        return \"No error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run these a few times and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\github\\langChain-v0.3\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 10/10 [00:27<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    generate_random_number()\n",
    "    generate_string_delay(\"Hello boss\")\n",
    "    try:\n",
    "        random_error()\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those traces should now be visible in the LangSmith UI, again under the same project:\n",
    "\n",
    "\n",
    "\n",
    "![LangSmith UI filters](../assets/value_error.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various other things we can do within the UI, but we'll leave that for you to explore.\n",
    "\n",
    "Finally, we can also modify our traceable names if we'd like to make them more readable inside the UI. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable(name=\"Chitchat Maker\")\n",
    "def error_generation_function(question: str):\n",
    "    delay = random.randint(0, 3)\n",
    "    time.sleep(delay)\n",
    "    number = random.randint(0, 1)\n",
    "    if number == 0:\n",
    "        raise ValueError(\"Random error\")\n",
    "    else:\n",
    "        return \"I'm great how are you?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this a few times and see what we get in LangSmith.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "    try:\n",
    "        error_generation_function(\"How are you today?\")\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter for the `Chitchat Maker` traceable and see our results.\n",
    "\n",
    "![LangSmith Chitchat Maker runs](../assets/chaitchat_maker.png)\n",
    "\n",
    "We can see our runs and their related metadata! That's it for this intro to LangSmith. As we work through the course we will (optionally) refer to LangSmith for digging into our runs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langChain-v0.3 (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
